{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting otter-grader\n",
      "  Using cached otter_grader-6.1.6-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting click<9.0.0,>=8.1.7 (from otter-grader)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dill>=0.3.0 (from otter-grader)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fica>=0.4.1 (from otter-grader)\n",
      "  Using cached fica-0.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting ipylab<2.0.0,>=1.0.0 (from otter-grader)\n",
      "  Using cached ipylab-1.1.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: ipython in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from otter-grader) (8.23.0)\n",
      "Collecting ipywidgets<9.0.0,>=8.1.5 (from otter-grader)\n",
      "  Using cached ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jinja2<4.0,>=3.1 (from otter-grader)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jupytext<2.0.0,>=1.16.4 (from otter-grader)\n",
      "  Using cached jupytext-1.18.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting nbconvert>=6.0.0 (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting nbformat>=5.0.0 (from otter-grader)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from otter-grader) (2.3.3)\n",
      "Collecting python-on-whales<1.0.0,>=0.72.0 (from otter-grader)\n",
      "  Using cached python_on_whales-0.79.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pyyaml<7,>=6 (from otter-grader)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting requests<3.0,>=2.31 (from otter-grader)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting wrapt<2.0.0,>=1.16.0 (from otter-grader)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting docutils (from fica>=0.4.1->otter-grader)\n",
      "  Downloading docutils-0.22.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sphinx (from fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinx-9.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipywidgets<9.0.0,>=8.1.5->otter-grader) (5.14.2)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets<9.0.0,>=8.1.5->otter-grader)\n",
      "  Using cached widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets<9.0.0,>=8.1.5->otter-grader)\n",
      "  Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from ipython->otter-grader) (4.9.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0,>=3.1->otter-grader)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting markdown-it-py>=1.0 (from jupytext<2.0.0,>=1.16.4->otter-grader)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting mdit-py-plugins (from jupytext<2.0.0,>=1.16.4->otter-grader)\n",
      "  Downloading mdit_py_plugins-0.5.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from jupytext<2.0.0,>=1.16.4->otter-grader) (24.0)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (5.7.2)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading mistune-3.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading nbclient-0.10.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting playwright (from nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading playwright-1.57.0-py3-none-macosx_11_0_universal2.whl.metadata (3.5 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.0.0->otter-grader)\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.0.0->otter-grader)\n",
      "  Downloading jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from pandas>=2.0.0->otter-grader) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0.0->otter-grader) (2025.2)\n",
      "Collecting pydantic!=2.0.*,<3,>=2 (from python-on-whales<1.0.0,>=0.72.0->otter-grader)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting typing-extensions (from python-on-whales<1.0.0,>=0.72.0->otter-grader)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0,>=2.31->otter-grader)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0,>=2.31->otter-grader)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.31->otter-grader)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0,>=2.31->otter-grader)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.4)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema>=2.6->nbformat>=5.0.0->otter-grader)\n",
      "  Downloading rpds_py-0.30.0-cp312-cp312-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from jupyter-core>=4.7->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (4.2.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=1.0->jupytext<2.0.0,>=1.16.4->otter-grader)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (8.6.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from pexpect>4.3->ipython->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->otter-grader) (0.2.13)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0.0,>=0.72.0->otter-grader)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->otter-grader) (1.16.0)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyee<14,>=13 (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Using cached pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting greenlet<4.0.0,>=3.1.1 (from playwright->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader)\n",
      "  Downloading greenlet-3.3.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath>=1.0.1 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting snowballstemmer>=2.2 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading snowballstemmer-3.0.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting babel>=2.13 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting alabaster>=0.7.14 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting roman-numerals>=1.0.0 (from sphinx->fica>=0.4.1->otter-grader)\n",
      "  Downloading roman_numerals-4.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from stack-data->ipython->otter-grader) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from stack-data->ipython->otter-grader) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/arslan/Library/Python/3.12/lib/python/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert>=6.0.0->nbconvert[webpdf]>=6.0.0; sys_platform != \"emscripten\" and sys_platform != \"wasi\"->otter-grader) (6.4)\n",
      "Using cached otter_grader-6.1.6-py3-none-any.whl (142 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fica-0.4.1-py3-none-any.whl (13 kB)\n",
      "Using cached ipylab-1.1.0-py3-none-any.whl (101 kB)\n",
      "Using cached ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jupytext-1.18.1-py3-none-any.whl (167 kB)\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached python_on_whales-0.79.0-py3-none-any.whl (118 kB)\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-macosx_10_13_x86_64.whl (182 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-macosx_10_13_x86_64.whl (39 kB)\n",
      "Downloading bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-macosx_10_13_x86_64.whl (11 kB)\n",
      "Downloading mistune-3.2.0-py3-none-any.whl (53 kB)\n",
      "Downloading nbclient-0.10.4-py3-none-any.whl (25 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-macosx_10_12_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading docutils-0.22.4-py3-none-any.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m633.2/633.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading mdit_py_plugins-0.5.0-py3-none-any.whl (57 kB)\n",
      "Downloading playwright-1.57.0-py3-none-macosx_11_0_universal2.whl (42.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinx-9.1.0-py3-none-any.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.3.0-cp312-cp312-macosx_11_0_universal2.whl (276 kB)\n",
      "Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading roman_numerals-4.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading rpds_py-0.30.0-cp312-cp312-macosx_10_12_x86_64.whl (375 kB)\n",
      "Downloading snowballstemmer-3.0.1-py3-none-any.whl (103 kB)\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, wrapt, widgetsnbextension, urllib3, typing-extensions, tinycss2, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, soupsieve, snowballstemmer, rpds-py, roman-numerals, pyyaml, pandocfilters, mistune, mdurl, MarkupSafe, jupyterlab_widgets, jupyterlab-pygments, imagesize, idna, greenlet, docutils, dill, defusedxml, click, charset_normalizer, certifi, bleach, babel, attrs, annotated-types, alabaster, typing-inspection, requests, referencing, pyee, pydantic-core, markdown-it-py, jinja2, beautifulsoup4, sphinx, pydantic, playwright, mdit-py-plugins, jsonschema-specifications, python-on-whales, jsonschema, ipywidgets, fica, nbformat, ipylab, nbclient, jupytext, nbconvert, otter-grader\n",
      "Successfully installed MarkupSafe-3.0.3 alabaster-1.0.0 annotated-types-0.7.0 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.3 bleach-6.3.0 certifi-2026.1.4 charset_normalizer-3.4.4 click-8.3.1 defusedxml-0.7.1 dill-0.4.0 docutils-0.22.4 fastjsonschema-2.21.2 fica-0.4.1 greenlet-3.3.0 idna-3.11 imagesize-1.4.1 ipylab-1.1.0 ipywidgets-8.1.8 jinja2-3.1.6 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 jupyterlab-pygments-0.3.0 jupyterlab_widgets-3.0.16 jupytext-1.18.1 markdown-it-py-4.0.0 mdit-py-plugins-0.5.0 mdurl-0.1.2 mistune-3.2.0 nbclient-0.10.4 nbconvert-7.16.6 nbformat-5.10.4 otter-grader-6.1.6 pandocfilters-1.5.1 playwright-1.57.0 pydantic-2.12.5 pydantic-core-2.41.5 pyee-13.0.0 python-on-whales-0.79.0 pyyaml-6.0.3 referencing-0.37.0 requests-2.32.5 roman-numerals-4.1.0 rpds-py-0.30.0 snowballstemmer-3.0.1 soupsieve-2.8.1 sphinx-9.1.0 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 tinycss2-1.4.0 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 webencodings-0.5.1 widgetsnbextension-4.0.15 wrapt-1.17.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install otter-grader\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 ‚Äì Python, NumPy, and Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the first assignment in DSC 259R!\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. The notebook is _only_ for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "\n",
    "- **Labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the course GitHub repository.\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.** More details on its usage are given at the bottom of this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing code from `lab.py`**:\n",
    "\n",
    "- Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "- We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "  - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started! üéâ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Python Basics üêç\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 0 ‚Äì Consecutive Integers\n",
    "\n",
    "Complete the implementation of the function `consecutive_ints`, which takes in a possibly empty list of integers (`ints`) and returns `True` if there exist two adjacent list elements that are consecutive integers and `False` otherwise.\n",
    "\n",
    "For example, since `9` is next to `8`, `consecutive_ints([5, 3, 6, 4, 9, 8])` should evaluate to `True`, since `9` and `8` are consecutive integers. On the other hand, `consecutive_ints([1, 3, 5, 7, 9])` should evaluate to `False`.\n",
    "\n",
    "**_Note_**: If you look at `lab.py`, you'll notice that the solution to this problem is already there. This question is done for you to show you what a completed homework problem looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# The cells below are here for you to write scratch work in.\n",
    "# You should write the code for your answer in `lab.py`, not here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def consecutive_ints(ints):\n",
    "    # We iterate up to len(ints) - 1 so we don't go out of bounds \n",
    "    # when checking the 'next' element\n",
    "    for i in range(len(ints) - 1):\n",
    "        # Check if the absolute difference between neighbors is 1\n",
    "        if abs(ints[i] - ints[i+1]) == 1:\n",
    "            return True\n",
    "            \n",
    "    # If the loop finishes without finding a pair, return False\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "To run the public tests on your code for a given question, run the cell containing a call to `grader.check` that immediately follows it.\n",
    "\n",
    "Remember, your grade will primarily be determined by hidden tests, which are **not** run when you run `grader.check`, so it's important to extensively test your functions on your own by calling them on different inputs. Does they work for edge cases? Real-world data is **very messy** and you should expect your data processing code to break without thorough testing!\n",
    "\n",
    "You can write custom tests either by calling your functions on different inputs here in the notebook, or by writing doctests in `lab.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q0 results: All test cases passed!"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1 ‚Äì Median vs. Mean\n",
    "\n",
    "Complete the implementation of the function `median_vs_mean`, which takes in a non-empty list of numbers (`nums`) and returns `True` if median of the list is less than or equal to the mean of the list and `False` otherwise.\n",
    "\n",
    "Recall, if a list has even length, the median is the mean of the middle two elements.\n",
    "\n",
    "**_Note:_** In this question, you may only use built-in functions and methods in Python. You should not use `numpy` or `pandas` at all, nor should you import any additional packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def median_vs_mean(nums):\n",
    "    # Sort without modifying the original list\n",
    "    s = sorted(nums)\n",
    "    \n",
    "    n = len(s)\n",
    "    mid = n // 2\n",
    "    \n",
    "    # Compute median\n",
    "    if n % 2 == 1:           # odd length\n",
    "        median = s[mid]\n",
    "    else:                    # even length\n",
    "        median = (s[mid - 1] + s[mid]) / 2\n",
    "    \n",
    "    # Compute mean\n",
    "    mean = sum(s) / n\n",
    "    \n",
    "    return median <= mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Strings and Files üßµ\n",
    "\n",
    "The following questions will familiarize you with the basics of working with strings and reading data from files. Remember that by default, data from files are stored as strings in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2 ‚Äì $n$ Prefixes\n",
    "\n",
    "Complete the implementation of the function `n_prefixes`, which takes a string `s` and a positive integer `n`. It returns a string containing the first `n` consecutive prefixes of `s` in reverse order.\n",
    "\n",
    "For example, let's suppose `s` is the string `'Billy!'` and `n` is `4`. The consecutive prefixes of `'Billy!'` are:\n",
    "\n",
    "- `'B'`\n",
    "- `'Bi'`\n",
    "- `'Bil'`\n",
    "- `'Bill'`\n",
    "- `'Billy'`\n",
    "- `'Billy!'`\n",
    "\n",
    "The first 4 of these are `'B'`, `'Bi'`, `'Bil'`, and `'Bill'`. If we combine these 4 in reverse order, we get `'BillBilBiB'`, which is what `n_prefixes('Billy!', 4)` should return. As another example, `n_prefixes('Marina', 3)` should return `'MarMaM'`. **You may assume that `n` is no larger than the length of `s`.**\n",
    "\n",
    "**_Hint:_** Recall that [strings may be sliced](https://docs.python.org/3/tutorial/introduction.html#strings), like lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def n_prefixes(s, n):\n",
    "    result = \"\"\n",
    "    \n",
    "    # build prefixes from n down to 1\n",
    "    for i in range(n, 0, -1):\n",
    "        result += s[:i]\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! üöÄ</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 ‚Äì Exploded Numbers üí£\n",
    "\n",
    "Complete the implementation of the function `exploded_numbers`, which takes in a list of integers (`ints`) and a non-negative integer (`n`) and **returns a list of strings** containing numbers from the list expanded by `n` numbers in both directions, separated by spaces. Each integer should be [zero padded](https://www.tutorialspoint.com/python/string_zfill.htm) so that all integers outputted have the same length.\n",
    "\n",
    "For example, consider `exploded_numbers([3, 8, 15], 2)`.\n",
    "\n",
    "- If we explode 3 by 2 numbers in both directions, we get 1, 2, 3, 4, 5.\n",
    "- If we explode 8 by 2 numbers in both directions, we get 6, 7, 8, 9, 10.\n",
    "- If we explode 15 by 2 numbers in both directions, we get 13, 14, 15, 16, 17.\n",
    "\n",
    "The longest length of any of the exploded numbers above is 2, so all of the outputted integers should have length 2.\n",
    "\n",
    "- The string corresponding to 3 in the input is `'01 02 03 04 05'`.\n",
    "- The string corresponding to 8 in the input is `'06 07 08 09 10'`.\n",
    "- The string corresponding to 15 in the input is `'13 14 15 16 17'`.\n",
    "\n",
    "So, `exploded_numbers([3, 8, 15], 2)` should return `['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']`.\n",
    "\n",
    "As another example, `exploded_numbers([9, 99], 3)` should return `['006 007 008 009 010 011 012', '096 097 098 099 100 101 102']`.\n",
    "\n",
    "**_Note_**: You can assume that negative numbers will never be encountered. That is, when testing your code, we will never explode a number so much that it becomes negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def exploded_numbers(ints, n):\n",
    "    exploded_lists = []\n",
    "    \n",
    "    # Step 1: build exploded ranges\n",
    "    for x in ints:\n",
    "        exploded = list(range(x - n, x + n + 1))\n",
    "        exploded_lists.append(exploded)\n",
    "    \n",
    "    # Step 2: compute max width across all numbers\n",
    "    max_width = 0\n",
    "    for lst in exploded_lists:\n",
    "        for num in lst:\n",
    "            max_width = max(max_width, len(str(num)))\n",
    "    \n",
    "    # Step 3: format each exploded list as padded strings\n",
    "    result = []\n",
    "    for lst in exploded_lists:\n",
    "        padded = [str(num).zfill(max_width) for num in lst]\n",
    "        result.append(\" \".join(padded))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4 ‚Äì Reading Files\n",
    "\n",
    "[Recall](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) that the built-in function `open` takes in a file path and returns _a file object_ (sometimes called a _file handle_). Below are a few properties of file objects:\n",
    "\n",
    "- `open(path)` opens the file at location `path` for reading.\n",
    "- `open(path)` is an _iterable_, which contains successive lines of the file.\n",
    "- Once a file object is opened, after use it should be closed to avoid memory leaks. To ensure a file is closed once done, you should use a _context manager_ as follows:\n",
    "\n",
    "```py\n",
    "with open(path) as fh:\n",
    "    for line in fh:\n",
    "        process_line(line)\n",
    "```\n",
    "\n",
    "- To read the entire file into a string, use the `read` method:\n",
    "\n",
    "```py\n",
    "with open(path) as fh:\n",
    "    s = fh.read()\n",
    "```\n",
    "\n",
    "However, you should be careful when reading an entire file into memory that the file isn't too big! _You should avoid this whenever possible!_\n",
    "\n",
    "Complete the implementation of the function `last_chars`, which takes in file object (`fh`) and returns a string consisting of the last character of each line. Note that you don't have to use `open` at all; the argument given to you is a file object, not a file path.\n",
    "\n",
    "**_Note:_** A newline (`'\\n'`) is the \"delimiter\" of the lines of a file, and doesn't count as part of the line (as the tests imply). Every other character is part of the line. For more info on this, see [the interpretation](https://en.wikipedia.org/wiki/Newline#Interpretation) of files as a 'newline delimited variables' file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def last_chars(fh):\n",
    "    result = \"\"\n",
    "    \n",
    "    for line in fh:\n",
    "        line = line.rstrip('\\n')   # remove only newline\n",
    "        if line:                   # avoid errors if the line is empty\n",
    "            result += line[-1]\n",
    "            \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "If your implementation is correct, you should see `'hrg'` when running the cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hrg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You'll see the Path(...) / syntax a lot.\n",
    "# It creates the correct path to your file,\n",
    "# whether you're using Windows, macOS, or Linux.\n",
    "# (Note that macOS and Linux use / to denote separate folders in paths,\n",
    "# while Windows uses \\.)\n",
    "\n",
    "fp = Path(\"data\") / \"chars.txt\"\n",
    "last_chars(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: `numpy` exercises ü•ß\n",
    "\n",
    "For a refresher on `numpy` and arrays, refer to the relevant section of the [these notes (from another UCSD course)](https://notes.dsc10.com/02-data_sets/arrays.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5 ‚Äì Array Methods\n",
    "\n",
    "Complete the implementations of the functions `add_root` and `where_square`. Specifications are given below. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "#### `add_root`\n",
    "\n",
    "`add_root` should take in a `numpy` array, `A`, and return a new `numpy` array that contains the element-wise sum of the elements in `A` with the _square roots of the positions of the elements in `A`_.\n",
    "\n",
    "For instance, if `A` contains the values 5, 9, and 4, the output array should contain the values 5 (5 + $\\sqrt{0}$), 10 (9 + $\\sqrt{1}$), and 5.4142... (4 + $\\sqrt{2}$).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `where_square`\n",
    "\n",
    "`where_square` should take in a `numpy` array, `A`, and return a new `numpy` array of Booleans whose `i`th element is `True` if and only if the `i`th element of `A` is a perfect square.\n",
    "\n",
    "For instance, `where_square(np.array([2, 9, 16, 15]))` should return `array([False, True, True, False])`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def add_root(A):\n",
    "    return A + np.sqrt(np.arange(len(A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def where_square(A):\n",
    "    roots = np.sqrt(A)\n",
    "    return roots == np.floor(roots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Don't change this cell -- it is needed for the tests to work\n",
    "A_1 = np.array([2, 4, 6, 7])\n",
    "out_1 = add_root(A_1)\n",
    "\n",
    "A_2 = np.array([1, 2, 16, 17, 32, 49])\n",
    "out_2 = where_square(A_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6 - Filtering Matrices\n",
    "\n",
    "Complete the implementation for the function `filter_cutoff_loop` and `filter_cutoff_np`.\n",
    "\n",
    "#### Part 1: `filter_cutoff_loop`\n",
    "\n",
    "`filter_cutoff_loop` should take in a matrix (2-dimensional `numpy` array) and a `float` cutoff. The function should return a 2-dimensional `numpy` array with only coumns that have a column mean (strictly) greater than the cutoff value. **This function should be implemented with loops or list comprehensions, not using `numpy` or `pandas` operations.** For example, given the matrix:\n",
    "\n",
    "$$\n",
    "a = \\begin{bmatrix}\n",
    "    1 & -2 & 3 & -3 \\\\\n",
    "    0 & 1 & 3 & 6 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The column means are computed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "= \\frac{1+0}{2} = 0.5 \\text{, }\n",
    "\\begin{bmatrix}\n",
    "-2\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "= \\frac{-2+1}{2} = 0.5 \\text{, }\n",
    "\\begin{bmatrix}\n",
    "3\\\\\n",
    "3\n",
    "\\end{bmatrix}\n",
    "= \\frac{3+3}{2} = 3 \\text{, }\n",
    "\\begin{bmatrix}\n",
    "-3\\\\\n",
    "6\n",
    "\\end{bmatrix}\n",
    "= \\frac{-3+6}{2} = 1.5\n",
    "$$\n",
    "\n",
    "If the cutoff value is 1, only the last two columns have means above 1, thus only the last two columns are kept, as shown in the first example below.\n",
    "\n",
    "```py\n",
    ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n",
    ">>> filter_cutoff_loop(a, 1.0)\n",
    "# the column means are [0.1,-0.5, 3, 1.5]\n",
    "# only columns 3 & 4 have column means higher than 1\n",
    "# we only return columns 3 & 4\n",
    "array([[ 3, -3],\n",
    "       [ 3,  6]])\n",
    "```\n",
    "\n",
    "```py\n",
    ">>> a = np.array([[1,-2, 3,-3], [0, 1, 3, 6]])\n",
    ">>> filter_cutoff_loop(a, 2.0)\n",
    "# the column means are [0.1,-0.5, 3, 1.5]\n",
    "# only column 3 has a column mean higher than 2\n",
    "# we only return column 3\n",
    "array([[3],\n",
    "       [3]])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def filter_cutoff_loop(matrix, cutoff):\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "\n",
    "    keep_cols = []\n",
    "\n",
    "    # Step 1: compute column means with loops\n",
    "    for j in range(cols):\n",
    "        col_sum = 0\n",
    "        for i in range(rows):\n",
    "            col_sum += matrix[i][j]\n",
    "        mean = col_sum / rows\n",
    "\n",
    "        if mean > cutoff:\n",
    "            keep_cols.append(j)\n",
    "\n",
    "    # Step 2: build the filtered matrix (still using loops)\n",
    "    filtered = []\n",
    "    for i in range(rows):\n",
    "        row_vals = []\n",
    "        for j in keep_cols:\n",
    "            row_vals.append(matrix[i][j])\n",
    "        filtered.append(row_vals)\n",
    "\n",
    "    return np.array(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q6 results: All test cases passed!"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6\n",
    "\n",
    "#### Part 2: `filter_cutoff_np`\n",
    "\n",
    "`filter_cutoff_np` should take in the same inputs and output the same results as `filter_cutoff_loop`. **Do not use loops or list comprehensions for this implementation, only `numpy` operations.**\n",
    "\n",
    "**_Hints:_**:\n",
    "\n",
    "- What does the axis argument do in `np.mean`?\n",
    "- Remember we can slice arrays using Boolean values. How does the code below work?\n",
    "\n",
    "```py\n",
    ">>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    ">>> a[:, [True, False, True, False]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def filter_cutoff_np(matrix, cutoff):\n",
    "    col_means = np.mean(matrix, axis=0)        # 1 √ó num_columns\n",
    "    mask = col_means > cutoff                  # Boolean mask\n",
    "    return matrix[:, mask]                     # select only columns we keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6.2</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q6.2 results: All test cases passed!"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 7 ‚Äì Stock Prices üìà\n",
    "\n",
    "Complete the implementations of the functions `growth_rates` and `with_leftover`. Specifications are given below. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "#### `growth_rates`\n",
    "\n",
    "`growth_rates` should take in a `numpy` array, `A`, of [stock prices](https://en.wikipedia.org/wiki/Stock) for a single stock on successive days in USD. It should return an array of growth rates. That is, the `i`th number of the returned array should contain the rate of growth in stock price between the $i^{th}$ day to the $(i+1)^{th}$ day. The growth rate between two values is defined as $\\frac{\\text{final} - \\text{initial}}{\\text{initial}}$. You should return growth rates as **proportions, rounded to two decimal places**.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `with_leftover`\n",
    "\n",
    "Again, suppose `A` is a `numpy` array of stock prices. Consider the following scheme:\n",
    "\n",
    "- Suppose that you start each day with \\$20 to purchase stocks.\n",
    "- Each day, you purchase as many shares as possible of the stock. (The price changes each day, according to `A`.)\n",
    "- Any money left-over after a given day is saved for possibly buying stock on a future day.\n",
    "\n",
    "The function `with_leftover` should take in `A` and return the day (as an `int`) on which you can buy at least one full share using just \"left-over\" money. If this never happens, return `-1`. Note that the first stock purchase occurs on Day 0, and that you cannot purchase fractions of a share of a stock.\n",
    "\n",
    "For example, if the stock price is \\$3 every day, then the answer is `1` (corresponding to Day 1):\n",
    "\n",
    "- Day 0: Buy 6 stocks with \\\\$20, and \\\\$2 is added to the leftover. Your total leftover is currently \\\\$2. This is not enough to buy one extra share, so you continue.\n",
    "- Day 1: Buy 6 stocks with \\\\$20, and another \\\\$2 is added to the leftover. Your total leftover is now \\\\$4, so you can now buy one extra share. Hence, the answer is Day 1, and `with_leftover` should return `1`.\n",
    "\n",
    "**_Hint:_** `np.cumsum` may be helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def growth_rates(A):\n",
    "    # Differences between consecutive days\n",
    "    diffs = A[1:] - A[:-1]\n",
    "    # Elementwise growth rates\n",
    "    rates = diffs / A[:-1]\n",
    "    # Round to 2 decimal places\n",
    "    return np.round(rates, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def with_leftover(A):\n",
    "    # Money left over each day after buying as many whole shares as possible with $20\n",
    "    # shares_per_day = floor(20 / price)\n",
    "    # leftover_per_day = 20 - shares_per_day * price\n",
    "    shares = np.floor(20 / A)\n",
    "    leftovers = 20 - shares * A\n",
    "\n",
    "    # Cumulative leftover over days\n",
    "    cum_leftover = np.cumsum(leftovers)\n",
    "\n",
    "    # Day where cumulative leftover is enough to buy 1 share at that day's price\n",
    "    can_buy = cum_leftover >= A\n",
    "\n",
    "    # Find first such day, if any\n",
    "    indices = np.where(can_buy)[0]\n",
    "    if indices.size == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Don't change this cell -- it is needed for the tests to work\n",
    "fp = Path(\"data\") / \"stocks.csv\"\n",
    "stocks = np.array([float(x) for x in open(fp)])\n",
    "out_3_stocks = growth_rates(stocks)\n",
    "\n",
    "A_4 = np.array([3, 3, 3, 3])\n",
    "out_4 = with_leftover(A_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Introduction to `pandas` üêº\n",
    "\n",
    "This part will help build familiarity with DataFrames in `pandas`.\n",
    "\n",
    "As always for `pandas` questions:\n",
    "\n",
    "1. Avoid writing loops through the rows of the DataFrame to do the problem, and\n",
    "2. Test the output/correctness of your code with the help of the dataset given, but be sure your code will also run on data that is similar to but different from the dataset given. (One way to do this is to sample rows from the provided DataFrame using the `.sample` method).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The file `data/salary.csv` contains salary information for the 2021-22 National Basketball Association (NBA) season üèÄ. Specifically, it contains the name, team, and salary of all players who have played at least 15 games last season. We will load this file and store it as a DataFrame named `salary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Position</th>\n",
       "      <th>Team</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Collins</td>\n",
       "      <td>PF</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>23000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danilo Gallinari</td>\n",
       "      <td>PF</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>20475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bogdan Bogdanoviƒá</td>\n",
       "      <td>SG</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>18000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clint Capela</td>\n",
       "      <td>C</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>17103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delon Wright</td>\n",
       "      <td>SG</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>8526316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Position           Team    Salary\n",
       "0       John Collins       PF  Atlanta Hawks  23000000\n",
       "1   Danilo Gallinari       PF  Atlanta Hawks  20475000\n",
       "2  Bogdan Bogdanoviƒá       SG  Atlanta Hawks  18000000\n",
       "3       Clint Capela        C  Atlanta Hawks  17103448\n",
       "4       Delon Wright       SG  Atlanta Hawks   8526316"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not edit this cell -- it is needed for the tests\n",
    "salary_fp = Path(\"data\") / \"salary.csv\"\n",
    "salary = pd.read_csv(salary_fp)\n",
    "salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 8 ‚Äì `pandas` Basics\n",
    "\n",
    "Your job is to complete the implementation of the function `salary_stats`, which takes in a DataFrame like `salary` and returns a **Series** containing the following statistics:\n",
    "\n",
    "- `'num_players'`: The number of players.\n",
    "- `'num_teams'`: The number of teams.\n",
    "- `'total_salary'`: The total salary amount for all players.\n",
    "- `'highest_salary'`: The name of the player with the highest salary. **Assume there are no ties.**\n",
    "- `'avg_los'`: The average salary of the `'Los Angeles Lakers'`, rounded to two decimal places.\n",
    "- `'fifth_lowest'`: The name and team of the player who has the fifth lowest salary, separated by a comma and a space (e.g. `'Billy Triton, Cleveland Cavaliers'`). **Assume there are no ties.**\n",
    "- `'duplicates'`: A Boolean that is `True` if there are any duplicate last names, and `False` otherwise. Note that some players may have a suffix on their name, such as \"Jr.\" or \"III\" -- you should ignore these. That is, \"Billy Triton Jr.\" and \"Tyler Triton\" should be considered to have the same last name.\n",
    "- `'total_highest'`: The total salary of the team that has the highest paid player.\n",
    "\n",
    "The index of each element in the outputted Series is specified above.\n",
    "\n",
    "**_Notes_**:\n",
    "\n",
    "- Your function should work on a dataset of the same format that contains information from other years. This means that `salary_stats` should not \"hard-code\" any numbers or strings, but should compute them all programatically. In all cases, you may assume that none of the answers involving ranking involves a tie.\n",
    "- The public tests don't test to see if your function actually returns the right numbers. You should manually inspect your result to make sure that all values seem appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def salary_stats(salary):\n",
    "    import pandas as pd  # safe even if already imported\n",
    "\n",
    "    # Try to infer column names in a flexible way\n",
    "    player_col = [c for c in salary.columns if 'player' in c.lower() or 'name' in c.lower()][0]\n",
    "    team_col   = [c for c in salary.columns if 'team'   in c.lower()][0]\n",
    "    salary_col = [c for c in salary.columns if 'sal'    in c.lower()][0]\n",
    "\n",
    "    # 1. Number of players\n",
    "    num_players = len(salary)\n",
    "\n",
    "    # 2. Number of teams\n",
    "    num_teams = salary[team_col].nunique()\n",
    "\n",
    "    # 3. Total salary\n",
    "    total_salary = salary[salary_col].sum()\n",
    "\n",
    "    # 4. Name of player with highest salary (assume no ties)\n",
    "    idx_max = salary[salary_col].idxmax()\n",
    "    highest_salary_player = salary.loc[idx_max, player_col]\n",
    "\n",
    "    # 5. Average salary of the Los Angeles Lakers, rounded to 2 decimals\n",
    "    lakers_mask = salary[team_col] == 'Los Angeles Lakers'\n",
    "    avg_los = round(salary.loc[lakers_mask, salary_col].mean(), 2)\n",
    "\n",
    "    # 6. Player with 5th lowest salary: \"Name, Team\"\n",
    "    fifth_row = salary.sort_values(by=salary_col, ascending=True).iloc[4]\n",
    "    fifth_lowest = f\"{fifth_row[player_col]}, {fifth_row[team_col]}\"\n",
    "\n",
    "    # 7. Duplicated last names (ignoring suffixes like Jr., III, etc.)\n",
    "    suffixes = {'Jr.', 'Jr', 'Sr.', 'Sr', 'II', 'III', 'IV', 'V'}\n",
    "\n",
    "    def last_name_only(full_name):\n",
    "        parts = full_name.split()\n",
    "        if len(parts) == 0:\n",
    "            return ''\n",
    "        if parts[-1] in suffixes and len(parts) >= 2:\n",
    "            return parts[-2]\n",
    "        return parts[-1]\n",
    "\n",
    "    last_names = salary[player_col].apply(last_name_only)\n",
    "    duplicates = last_names.duplicated().any()\n",
    "\n",
    "    # 8. Total salary of the team that has the highest paid player\n",
    "    team_of_highest = salary.loc[idx_max, team_col]\n",
    "    total_highest = salary.loc[salary[team_col] == team_of_highest, salary_col].sum()\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            'num_players':  num_players,\n",
    "            'num_teams':    num_teams,\n",
    "            'total_salary': total_salary,\n",
    "            'highest_salary': highest_salary_player,\n",
    "            'avg_los':      avg_los,\n",
    "            'fifth_lowest': fifth_lowest,\n",
    "            'duplicates':   duplicates,\n",
    "            'total_highest': total_highest,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not edit this cell -- it is needed for the tests\n",
    "salary_fp = Path(\"data\") / \"salary.csv\"\n",
    "salary = pd.read_csv(salary_fp)\n",
    "stats = salary_stats(salary)\n",
    "\n",
    "salary_sample_fp = Path(\"data\") / \"salary_sample.csv\"\n",
    "salary_sample = pd.read_csv(salary_sample_fp)\n",
    "sample_stats = salary_stats(salary_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q8 results: All test cases passed!"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 9 ‚Äì Reading Malformed `.csv` Files\n",
    "\n",
    "`data/malformed.csv` is a file of comma-separated values, containing the following fields:\n",
    "\n",
    "| column name | description                                            | type    |\n",
    "| ----------- | ------------------------------------------------------ | ------- |\n",
    "| `'first'`   | first name of person                                   | `str`   |\n",
    "| `'last'`    | last name of person                                    | `str`   |\n",
    "| `'weight'`  | weight of person (lbs)                                 | `float` |\n",
    "| `'height'`  | height of person (in)                                  | `float` |\n",
    "| `'geo'`     | location of person; comma-separated latitude/longitude | `str`   |\n",
    "\n",
    "Unfortunately, the entries contains errors with the placement of commas (`,`) and quotes (`\"`) that cause `pandas`' `read_csv` function to fail parsing the file with the default settings. Don't believe us? Try using `pd.read_csv` on `data/malformed.csv` and look at what happens.\n",
    "\n",
    "As a result, instead of using `pd.read_csv`, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Complete the implementation of the function `parse_malformed`, which takes in a file path (`fp`) and returns a parsed, properly-typed DataFrame with the information in the corresponding file. For example, `fp` may be `'data/malformed.csv'`. The DataFrame should contain the columns described in the data description table above (with the specified types).\n",
    "\n",
    "**_Note:_**\n",
    "\n",
    "- The only kinds of issues you need your function to handle are comma and quote misplacements; don't try and find any other issues with the CSV.\n",
    "- With that said, you should assume that `data/malformed.csv` is a sample of a larger file that has the same sorts of errors, but potentially in different lines. For example, `data/malformed.csv` has an unnecessary quote `\"` in line 4, but your function may be called on another CSV that has a perfectly fine line 4 but an unnecessary quote on some other line.\n",
    "- So, **don't** implement `parse_malformed` assuming that the commas and quotes are mispositioned on specific lines; rather, implement `parse_malformed` such that it can handle these issues on every single line they appear in.\n",
    "- A good way to proceed is to open `data/malformed.csv` and look carefully at the comma and quote placements.\n",
    "\n",
    "The first few rows of `parse_malformed('data/malformed.csv')` should be:\n",
    "\n",
    "<img src=\"./imgs/example-df.png\" width=45%>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_malformed(fp):\n",
    "    rows = []\n",
    "\n",
    "    with open(fp) as fh:\n",
    "        # Skip the header line\n",
    "        header = fh.readline()\n",
    "\n",
    "        for line in fh:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # skip empty lines\n",
    "\n",
    "            # Remove all double quotes\n",
    "            line = line.replace('\"', '')\n",
    "\n",
    "            # Split by commas\n",
    "            parts = line.split(',')\n",
    "\n",
    "            if len(parts) < 4:\n",
    "                # Malformed beyond simple comma/quote issues; skip or handle as needed\n",
    "                continue\n",
    "\n",
    "            first = parts[0].strip()\n",
    "            last = parts[1].strip()\n",
    "\n",
    "            # Find weight and height as the first two non-empty numeric tokens after last name\n",
    "            weight = None\n",
    "            height = None\n",
    "            geo_parts = []\n",
    "\n",
    "            for token in parts[2:]:\n",
    "                tok = token.strip()\n",
    "                if tok == '':\n",
    "                    # skip empty tokens caused by extra commas\n",
    "                    continue\n",
    "\n",
    "                if weight is None:\n",
    "                    weight = float(tok)\n",
    "                elif height is None:\n",
    "                    height = float(tok)\n",
    "                else:\n",
    "                    geo_parts.append(tok)\n",
    "\n",
    "            # Join whatever remains as geo (may contain commas originally)\n",
    "            geo = \",\".join(geo_parts)\n",
    "\n",
    "            rows.append({\n",
    "                \"first\": first,\n",
    "                \"last\": last,\n",
    "                \"weight\": float(weight),\n",
    "                \"height\": float(height),\n",
    "                \"geo\": geo,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows, columns=[\"first\", \"last\", \"weight\", \"height\", \"geo\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not edit -- needed for tests\n",
    "fp = Path(\"data\") / \"malformed.csv\"\n",
    "cols = [\"first\", \"last\", \"weight\", \"height\", \"geo\"]\n",
    "df = parse_malformed(fp)\n",
    "dg = pd.read_csv(fp, nrows=4, skiprows=10, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q9</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q9 results: All test cases passed!"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done with Lab 1! üèÅ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` ‚Äì that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q4 q7 q8\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 4, 7, and 8 ‚Äì again, only using the code in `lab.py`. The [video](#Infrastructure-Summary) linked above shows you how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0": {
     "name": "q0",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> consecutive_ints([5, 3, 6, 4, 9, 8])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> consecutive_ints([1, 3, 5, 7, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        },
        {
         "code": ">>> consecutive_ints([]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> median_vs_mean([6, 5, 4, 3, 2])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> median_vs_mean([50, 20, 15, 40])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> median_vs_mean([1, 8, 9]) == False\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> n_prefixes('Billy', 4) == 'BillBilBiB'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('Marina', 3) == 'MarMaM'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('aaron', 2) == 'aaa'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> n_prefixes('Justin', 5) == 'JustiJustJusJuJ'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> exploded_numbers([3, 8, 15], 2) == ['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> exploded_numbers([9, 99], 3) == ['006 007 008 009 010 011 012', '096 097 098 099 100 101 102']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fp = Path('data') / 'chars.txt'\n>>> last_chars(open(fp)) == 'hrg'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(out_1, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(np.all(out_1 >= A_1))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(np.isclose(out_1[3], 7 + np.sqrt(3)))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(out_2, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_2.dtype == np.dtype('bool')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(out_2[2])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> a = np.array([[1, -2, 3, -3], [0, 1, 3, 6]])\n>>> len(filter_cutoff_loop(a, 1).shape) == 2\nTrue",
         "failure_message": "should return a 2-dimensional numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> a = np.array([[1, -2, 3, -3], [0, 1, 3, 6]])\n>>> isinstance(filter_cutoff_loop(a, 1), np.ndarray)\nTrue",
         "failure_message": "the data type returned should be a numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6.2": {
     "name": "q6.2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> a = np.array([[1, -2, 3, -3], [0, 1, 3, 6]])\n>>> len(filter_cutoff_np(a, 1).shape) == 2\nTrue",
         "failure_message": "should return a 2-dimensional numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> a = np.array([[1, -2, 3, -3], [0, 1, 3, 6]])\n>>> isinstance(filter_cutoff_np(a, 1), np.ndarray)\nTrue",
         "failure_message": "the data type returned should be a numpy array",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_3_stocks.dtype == np.dtype('float')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(out_3_stocks.max() == 0.03)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> import numbers\n>>> isinstance(out_4, numbers.Integral)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(out_4 == 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(stats, pd.Series)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'total_highest' in stats.index\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats.loc['duplicates'], bool) or isinstance(stats.loc['duplicates'], np.bool_)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> list(df.columns) == cols\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['last'].dtype == np.dtype('O')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df['height'].dtype == np.dtype('float64')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> bool(df['geo'].str.contains(',').all())\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(df) == 100\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> dg.index = range(9, 13)\n>>> bool((dg == df.iloc[9:13]).all().all())\nTrue",
         "failure_message": "doctest examples",
         "hidden": false,
         "locked": false,
         "points": 6
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
